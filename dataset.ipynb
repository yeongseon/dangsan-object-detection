{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Author: Cl√©ment APAVOU\n",
    "'''\n",
    "import os, os.path as osp\n",
    "\n",
    "import ast\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from datasets.transforms import ToTensor\n",
    "\n",
    "from utils.logger import init_logger\n",
    "\n",
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LesionDataset(Dataset):\n",
    "    def __init__(self, data_path, mode='train'):\n",
    "        self.json_list = json2list(data_path)\n",
    "        self.mode = mode\n",
    "        self.file_name = [json_file['file_name'] for json_file in json_list]\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.labels = []\n",
    "            for data in json_list:\n",
    "                label = []\n",
    "                for shapes in data['shapes']:\n",
    "                    label.append(shapes['label'])\n",
    "                self.labels.append(label)\n",
    "            self.points = []\n",
    "            for data in json_list:\n",
    "                point = []\n",
    "                for shapes in data['shapes']:\n",
    "                    point.append(shapes['points'])\n",
    "                self.points.append(point)\n",
    "        self.imgs = [data['imageData'] for data in json_list]\n",
    "        \n",
    "        self.widths = [data['imageWidth'] for data in json_list]\n",
    "        self.heights = [data['imageHeight'] for data in json_list]\n",
    "        \n",
    "        self.label_map ={\n",
    "            '01_ulcer':1, '02_mass':2, '04_lymph':3, '05_bleeding':4\n",
    "        }\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "            transforms.RandomHorizontalFlip(p = 1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4452, 0.4457, 0.4464), (0.2592, 0.2596, 0.2600))\n",
    "        ])\n",
    "\n",
    "        self.transforms_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4452, 0.4457, 0.4464), (0.2592, 0.2596, 0.2600))\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        file_name = self.file_name[i]\n",
    "        img = Image.open(BytesIO(base64.b64decode(self.imgs[i])))\n",
    "        \n",
    "        target = {}\n",
    "        if self.mode == 'train':\n",
    "            img = self.transforms(img)\n",
    "            boxes = []\n",
    "            for point in self.points[i]:\n",
    "                x_min = int(np.min(np.array(point)[:,0]))\n",
    "                x_max = int(np.max(np.array(point)[:,0]))\n",
    "                y_min = int(np.min(np.array(point)[:,1]))\n",
    "                y_max = int(np.max(np.array(point)[:,1]))\n",
    "                boxes.append([x_min, y_min, x_max, y_max])\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "\n",
    "            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "            iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "\n",
    "            label = [self.label_map[label] for label in self.labels[i]]\n",
    "\n",
    "            masks = []\n",
    "            for box in boxes:\n",
    "                mask = np.zeros([int(self.heights[i]), int(self.widths[i])], np.uint8)\n",
    "                masks.append(cv2.rectangle(mask, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), 1, -1))\n",
    "\n",
    "            masks = torch.tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "            target[\"boxes\"] = boxes\n",
    "            target[\"labels\"] = torch.tensor(label, dtype=torch.int64)\n",
    "            target[\"masks\"] = masks\n",
    "            target[\"area\"] = area\n",
    "            target[\"iscrowd\"] = iscrowd\n",
    "        target[\"image_id\"] = torch.tensor([i], dtype=torch.int64)\n",
    "        if self.mode == 'test':\n",
    "            img = self.transforms_test(img)\n",
    "            target[\"file_name\"] = file_name\n",
    "            \n",
    "        return img, target\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def json2list(input_path):\n",
    "    train_files = sorted(glob(input_path + \"/*\"))\n",
    "        \n",
    "    train_json_list = []\n",
    "    for file in train_files:\n",
    "        with open(file, \"r\") as json_file:\n",
    "            train_json_list.append(json.load(json_file))\n",
    "    return train_json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83175/3252465913.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLesionDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./assets/lesion_detection/train/*'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_83175/106054654.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_path, mode)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLesionDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson2list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjson_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_83175/106054654.py\u001b[0m in \u001b[0;36mjson2list\u001b[0;34m(input_path)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjson2list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mtrain_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mtrain_json_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "train_set = LesionDataset('./assets/lesion_detection/train/*', mode='train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "od",
   "language": "python",
   "name": "od"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
